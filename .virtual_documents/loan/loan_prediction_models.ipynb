





# Importing required packages
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style='white')





train = pd.read_csv("final_train.csv")


train.info()


train = train.astype( {'Dependents' : 'str'})  # Convert Dependents to str 


train.info()


X = train.drop(columns=['LoanStatus'])
y = train.LoanStatus


X = pd.get_dummies(X)  # One Hot Encoding 


X.columns


X.sample(5)


X.shape





from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)


from sklearn.metrics import confusion_matrix, classification_report, accuracy_score


def print_scores(y_true, y_pred):
    cm = confusion_matrix(y_true,y_pred)
    tn = cm[0,0]
    tp = cm[1,1]
    fp = cm[0,1]
    fn = cm[1,0]
    print(f"Overall Accuracy                      : {(tp + tn) / (tp + fp + tn + fn):.2f}")
    print(f"Precision of Positive cases           : {tp / (tp + fp):.2f}")
    print(f"Precision of Negative cases           : {tn / (tn + fn):.2f}")
    print(f"Positive Recall or TPR or Sensitivity : {tp / (tp + fn):.2f}")
    print(f"Negative Recall or TNR or Specificity : {tn / (tn + fp):.2f}")      





# Importing packages logistic regression and evaluation 
from sklearn.linear_model import LogisticRegression


from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
ss.fit(X_train)


X_train_scaled = ss.transform(X_train)
X_test_scaled = ss.transform(X_test)


# logistic regression   - train model 
model = LogisticRegression()
model.fit(X_train_scaled,y_train)


# Check model's performance with train data 
model.score(X_train_scaled,y_train)


y_train_pred = model.predict(X_train_scaled)


accuracy_score(y_train,y_train_pred)


y_pred = model.predict(X_test_scaled)


accuracy_score(y_test,y_pred)


confusion_matrix(y_test,y_pred)


print_scores(y_test,y_pred)





print(classification_report(y_test,y_pred))


model.coef_


y_pred_prob = model.predict_proba(X_test_scaled)


y_pred_prob[5:10], y_pred[5:10]





from sklearn.tree import DecisionTreeClassifier


model = DecisionTreeClassifier(max_depth=3, min_samples_split=5)
model.fit(X_train,y_train)


model.score(X_train,y_train)


y_train_pred = model.predict(X_train)


print_scores(y_train,y_train_pred)


y_pred = model.predict(X_test)


print_scores(y_test,y_pred)


confusion_matrix(y_test,y_pred)


print(classification_report(y_test,y_pred))





# Print tree generated by DecisionTreeClassifier
from sklearn.tree import export_text
tree_rules = export_text(model, feature_names=list(X_train))
print(tree_rules)





from sklearn.neighbors import KNeighborsClassifier


model = KNeighborsClassifier(n_neighbors=3, n_jobs = 1)
model.fit(X_train_scaled,y_train)


y_train_pred = model.predict(X_train_scaled)


print_scores(y_train,y_train_pred)


y_pred = model.predict(X_test_scaled)


print_scores(y_test,y_pred)





from sklearn.naive_bayes import GaussianNB


model = GaussianNB()
model.fit(X_train,y_train)


y_train_pred = model.predict(X_train)


print_scores(y_train,y_train_pred)


y_pred = model.predict(X_test)


print_scores(y_test,y_pred)





from sklearn.svm import SVC


model = SVC()
model.fit(X_train_scaled,y_train)


y_train_pred = model.predict(X_train_scaled)


print_scores(y_train,y_train_pred)


y_pred = model.predict(X_test_scaled)


print_scores(y_test,y_pred)



