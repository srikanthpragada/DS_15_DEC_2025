import pandas as pd
import seaborn as sns
import numpy as np


df = pd.read_csv("reviews.csv") 


df.shape


df.sample(5)


# Remove all rows with null values
df.dropna(axis=0, inplace=True)


df.shape


# Change Is_Response to 0 for not happy and 1 for happy
df['Is_Response'] = df['Is_Response'].replace(['happy', 'not happy'],  ['1', '0'])


df.sample(5)


from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split 
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LogisticRegression


X = df['Description']
y = df['Is_Response']


# tf-idf means term-frequency times inverse document-frequency. 
tfidf = TfidfVectorizer(ngram_range=(1,1), stop_words='english')
tfidf.fit(X)
features = tfidf.transform(X)


features.shape


#eatures.toarray()[:10,500:520]


X_train, X_test, y_train, y_test = train_test_split(features,y,test_size=0.2,random_state=20)


clf = LogisticRegression().fit(X_train,y_train)


### Train accuracy
clf.score(X_train,y_train)


y_pred = clf.predict(X_test)
print("Accuracy Score:",clf.score(X_test,y_test))  


cm = confusion_matrix(y_test,y_pred)
print(cm)


from sklearn.metrics import classification_report
print( classification_report(y_test,y_pred))


group_counts = [f"{value:0.0f}" for value in  cm.flatten()]
group_names = ['TN','FP', 'FN','TP']
labels = [f"{v1}\n\n{v2}" for v1, v2 in zip(group_names,group_counts)]
labels = np.array(labels).reshape(2,2)
ax = sns.heatmap(cm, annot=labels, fmt="", cmap='RdYlBu',cbar=False)
ax.set_ylabel("Actual")
ax.set_xlabel("Predicted")





# tfidf.vocabulary_


# Predict whether the given review is positive or negative 
docs = ["This is very good",
        "Room service is not bad",
        "Food was awesome"]
# Tfidf
features = tfidf.transform(docs)
print(features.shape)
print(clf.predict(features))





# tf-idf means term-frequency times inverse document-frequency. 
tfidf = TfidfVectorizer(ngram_range=(1,1), stop_words='english')
features = tfidf.fit_transform(X).toarray()


#tfidf.vocabulary_.items()


features.shape


X_train, X_test, y_train, y_test = train_test_split(features,y,test_size=0.2,random_state=20)


from sklearn.naive_bayes import BernoulliNB
bnb = BernoulliNB().fit(X_train,y_train)


bnb.score(X_train,y_train)


y_pred = bnb.predict(X_test)
print("Accuracy Score:",bnb.score(X_test,y_test))  


from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,y_pred)
print(cm)
group_counts = [f"{value:0.0f}" for value in  cm.flatten()]
group_names = ['TN','FP', 'FN','TP']
labels = [f"{v1}\n\n{v2}" for v1, v2 in zip(group_names,group_counts)]
labels = np.array(labels).reshape(2,2)
ax = sns.heatmap(cm, annot=labels, fmt="", cmap='RdYlBu',cbar=False)
ax.set_ylabel("Actual")
ax.set_xlabel("Predicted")









